# ğŸ¤– Gemini Intelligence Scraper - Setup Guide

## âœ¨ Why Gemini?

- âœ… **FREE**: 1,500 requests/day (vs $3.50/batch with Bing)
- âœ… **Better Quality**: AI understands context like ChatGPT
- âœ… **No Rate Limiting**: Unlike DuckDuckGo HTML scraping (100% failure)
- âœ… **30 companies/day** vs 0 with DuckDuckGo

## ğŸ“‹ Quick Start

### 1. Get Your FREE Gemini API Key

1. Visit: https://aistudio.google.com/app/apikey
2. Click **"Create API Key"**
3. Copy your key (starts with `AIza...`)

### 2. Add API Key to Project

Open this file and paste your key:
```
config/gemini_api_key.txt
```

Replace `your-api-key-here` with your actual key.

### 3. Install Dependencies

**On PC (Windows):**
```bash
pip install google-generativeai
```

**On VPS (Linux):**
```bash
source venv/bin/activate
pip install google-generativeai
```

## ğŸ§ª Test Locally (Windows PC)

```bash
cd c:\Users\gerrit\Desktop\apihub

# Test with 3 companies
python src/utils/company_intelligence_scraper_gemini.py
```

**Expected output:**
```
ğŸ¤– GEMINI INTELLIGENCE SCRAPER (FREE TIER)
================================================================================
ğŸ“‹ Total companies in DB: 850
ğŸ“Œ Batch size: 30 companies
â³ Rate limit: ~2 requests/minute (30s delay)
================================================================================

[1/30] ğŸ¤– Gemini researching: MSC Shipmanagement Ltd (Fleet: 374 vessels)
  ğŸ“¡ Gemini response received (2453 chars)
  âœ“ Grants Subsidies: 0 findings
  âœ“ Legal Violations: 2 findings
  âœ“ Sustainability News: 1 findings
  âœ“ Reputation: 1 findings
  âœ“ Financial Pressure: 0 findings
  ğŸ“Š Total findings: 4
  â³ Waiting 30s (rate limit)...
```

## ğŸš€ Deploy to VPS

### Step 1: Stop Old Scraper (DuckDuckGo version)

```bash
ssh your-vps
sudo systemctl stop ais-intelligence-scraper
sudo systemctl disable ais-intelligence-scraper
```

### Step 2: Push to Git

**On PC:**
```bash
cd c:\Users\gerrit\Desktop\apihub
git add .
git commit -m "Add Gemini intelligence scraper (free tier)"
git push origin main
```

### Step 3: Deploy on VPS

**SSH to VPS:**
```bash
ssh your-vps
cd /var/www/apihub
git pull origin main

# Install Gemini package
source venv/bin/activate
pip install google-generativeai

# Add your API key
nano config/gemini_api_key.txt
# (Paste your API key, Ctrl+X to save)

# Create logs directory if needed
mkdir -p logs

# Copy systemd service
sudo cp config/systemd/ais-intelligence-scraper-gemini.service /etc/systemd/system/

# Enable and start
sudo systemctl daemon-reload
sudo systemctl enable ais-intelligence-scraper-gemini
sudo systemctl start ais-intelligence-scraper-gemini

# Check status
sudo systemctl status ais-intelligence-scraper-gemini
```

### Step 4: Monitor Logs

```bash
# Live tail (Ctrl+C to exit)
tail -f /var/www/apihub/logs/intelligence_scraper_gemini.log

# Or with systemd
sudo journalctl -u ais-intelligence-scraper-gemini -f
```

## ğŸ“Š Expected Results

### What You'll See

**Typical findings per company:**
- Legal Violations: 1-2 findings (fines, penalties)
- Sustainability News: 1-2 findings (initiatives, retrofits)
- Reputation: 0-1 findings (ratings, certifications)
- Grants/Subsidies: 0-1 findings (government funding)
- Financial Pressure: 0-1 findings (carbon costs)

**Success rate:** 60-80% of companies will have 1+ findings

### Output Files

**Progress file** (saves every 5 companies):
```
data/company_intelligence_gemini_progress.json
```

**Final file** (batch complete):
```
data/company_intelligence_gemini_20251117_143000.json
```

## ğŸ”§ Configuration

Edit `src/services/intelligence_scraper_service_gemini.py`:

```python
BATCH_SIZE = 30              # Companies per batch (free tier safe)
SLEEP_BETWEEN_BATCHES = 86400  # 24 hours
MAX_TOTAL_COMPANIES = 500    # Total limit
```

**Free tier limits:**
- 1,500 requests/day
- At 30 companies/day = **50 days** to scrape 500 companies
- Or increase to 50 companies/day = 30 days

## ğŸ†š Comparison: Gemini vs DuckDuckGo

| Feature | DuckDuckGo (Old) | Gemini (New) |
|---------|------------------|--------------|
| Cost | Free | Free |
| Success Rate | **0%** (100% timeouts) | **60-80%** |
| Companies/Day | 0 | 30-50 |
| Quality | N/A (doesn't work) | â­â­â­â­â­ |
| Rate Limits | Instant block | 1,500/day |
| Findings/Company | 0 | 2-4 avg |

## â“ Troubleshooting

### "Invalid API key"
- Check `config/gemini_api_key.txt`
- Make sure it starts with `AIza`
- No extra spaces or newlines

### "quota exceeded"
- You hit 1,500 requests/day limit
- Wait 24 hours or reduce `BATCH_SIZE`

### "JSON parse error"
- Gemini occasionally returns malformed JSON
- Scraper retries next company automatically
- Check logs for details

### No findings for certain companies
- Normal - smaller companies have less news
- Gemini searches real sources, won't invent data
- Focus: maritime industry sources (Lloyd's List, TradeWinds)

## ğŸ“ˆ Next Steps

1. **Test locally** with 3 companies
2. **Verify quality** of findings
3. **Deploy to VPS** with API key
4. **Monitor first batch** (30 companies)
5. **Check results** after 24 hours
6. **Download data** from dashboard: https://gerritsxd.com/ships/intelligence

## ğŸ¯ API Key Safety

**Never commit your API key!**

âœ… Already gitignored: `config/gemini_api_key.txt`

If you accidentally commit it:
```bash
# Revoke key at: https://aistudio.google.com/app/apikey
# Generate new key
# Update config file
```

---

**Questions?** The scraper logs everything verbosely. Check logs first!
