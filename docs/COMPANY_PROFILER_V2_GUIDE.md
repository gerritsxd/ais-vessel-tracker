# ğŸ¢ Company Profiler V2 - ML Training Data Collection

## Purpose

Collect comprehensive textual data about shipping companies for training an ML model to predict **WASP (Wind-Assisted Ship Propulsion) fit scores**. This replaces the broken v1 scraper that relied on DuckDuckGo HTML scraping.

---

## What's New in V2?

### âŒ V1 Problems Fixed:
- DuckDuckGo HTML scraping broken (status 202, anti-bot measures)
- All searches returned empty results
- No actual data collected
- Unreliable and rate-limited

### âœ… V2 Improvements:
1. **Wikipedia/Wikidata API** - Structured company data
2. **googlesearch-python** - Reliable Google search without API keys
3. **Smart website crawling** - Handles both static and JavaScript sites
4. **ML-ready output** - Clean text format perfect for training
5. **Robust error handling** - Continues even if sources fail
6. **Progress saving** - Resume from any point

---

## Installation

### 1. Install New Dependency

```bash
pip install googlesearch-python
```

Or update from requirements:
```bash
pip install -r config/requirements.txt
```

### 2. Optional: Playwright (for JavaScript sites)

Already installed, but if needed:
```bash
pip install playwright
playwright install chromium
```

---

## Quick Test

Test on a single company first:

```bash
python scripts/test_company_profiler.py
```

This will test on Maersk A/S and show you:
- Wikipedia data retrieval
- Google search results
- Website discovery
- Page crawling
- Final output quality

**Expected output**: 10,000-50,000 characters of text data

---

## Usage

### Basic Usage (5 companies, safe testing)

```bash
python src/utils/company_profiler_v2.py --max-companies 5 -v
```

### Process Specific Company

```bash
python src/utils/company_profiler_v2.py --company "Maersk" -v
```

### Large Batch (overnight run)

```bash
python src/utils/company_profiler_v2.py --max-companies 100 --max-pages-per-site 30
```

### Resume from Position

If interrupted at company #47:
```bash
python src/utils/company_profiler_v2.py --start-from 47 --max-companies 50
```

### Use Browser for JavaScript Sites

```bash
python src/utils/company_profiler_v2.py --max-companies 10 --use-browser -v
```

---

## Command Line Options

| Option | Description | Default |
|--------|-------------|---------|
| `--max-companies N` | Process N companies | 5 |
| `--max-pages-per-site N` | Crawl N pages per website | 50 |
| `--company "NAME"` | Filter companies containing NAME | None |
| `--start-from N` | Skip first N companies | 0 |
| `--use-browser` | Use Playwright (slower, handles JS) | False |
| `-v, --verbose` | Show detailed progress | False |

---

## Output Files

### 1. JSON Format (Structured)

**File**: `data/company_profiles_v2_TIMESTAMP.json`

```json
{
  "companies": {
    "Maersk A/S": {
      "company_name": "Maersk A/S",
      "search_date": "2025-11-17T12:00:00",
      "data_sources": {
        "wikipedia": {
          "title": "Maersk",
          "extract": "A.P. MÃ¸ller-MÃ¦rsk A/S is a Danish shipping..."
        },
        "google_search": {
          "search_results": ["https://maersk.com", ...]
        },
        "website_crawl": {
          "pages": [
            {"url": "...", "text": "...", "length": 5000},
            ...
          ]
        }
      }
    }
  }
}
```

### 2. ML Training Format (Plain Text)

**File**: `data/company_training_data_TIMESTAMP.txt`

```
================================================================================
COMPANY: Maersk A/S
================================================================================

--- WIKIPEDIA ---
A.P. MÃ¸ller-MÃ¦rsk A/S is a Danish shipping company, active in ocean and inland
freight transportation and associated services...

--- WEBSITE CONTENT (12 pages) ---

[https://www.maersk.com/]
Home - Maersk
Global leader in container shipping...
Fleet size: 700+ vessels
Annual revenue: $81.5 billion...

[https://www.maersk.com/about]
About Maersk
Founded in 1904...
```

This format is perfect for:
- Text embedding models
- NLP preprocessing
- Feature extraction
- Training data for vessel fit scoring

---

## Data Sources Priority

1. **Wikipedia** - Company overview, founding, size
2. **Google Search** - Find official websites and references
3. **Company Website** - Official information
4. **Website Crawl** - Deep textual content (10-50 pages)

---

## Performance

### Single Company (with verbose):
- Wikipedia: ~2-3 seconds
- Google search: ~5-10 seconds
- Website discovery: ~5 seconds
- Crawl 10 pages: ~30-60 seconds
- **Total**: ~1-2 minutes per company

### Batch Processing:
- **10 companies**: ~15-30 minutes
- **50 companies**: ~1.5-3 hours
- **100 companies**: ~3-6 hours
- **All 3,544 companies**: ~5-10 days (run in batches!)

### Rate Limiting:
- Delays: 3-7 seconds between requests
- Respects Google's rate limits
- Safe for long-term running

---

## Batch Processing Strategy

### Recommended Approach

Process in chunks of 50-100 companies:

```bash
# Batch 1: Companies 0-99
python src/utils/company_profiler_v2.py --max-companies 100 -v

# Batch 2: Companies 100-199
python src/utils/company_profiler_v2.py --start-from 100 --max-companies 100 -v

# Batch 3: Companies 200-299
python src/utils/company_profiler_v2.py --start-from 200 --max-companies 100 -v
```

### Overnight Run (Safe)

```bash
# Run for 8 hours max (~200 companies)
timeout 28800 python src/utils/company_profiler_v2.py --max-companies 500
```

### Supervised Run (Recommended)

```bash
# Small batches with manual verification
python src/utils/company_profiler_v2.py --max-companies 20 -v
# Check output quality
# Adjust settings if needed
# Continue with larger batches
```

---

## ML Model Integration

### For WASP Fit Score Prediction

The collected data will be used to:

1. **Extract Features**:
   - Company size (fleet, revenue)
   - Sustainability commitment
   - Innovation focus
   - Financial stability
   - Environmental policies

2. **Text Embeddings**:
   - Convert text to vectors using BERT/Sentence Transformers
   - Combine with vessel technical data
   - Create rich feature matrix

3. **Model Training**:
   - Input: Company text + vessel specs + emissions data
   - Output: WASP fit score (0-10)
   - Model: Gradient Boosting / Neural Network

4. **Generate Reports**:
   - Score justification
   - Risk factors
   - Recommendation confidence

---

## Troubleshooting

### "googlesearch-python not installed"

```bash
pip install googlesearch-python
```

### "Playwright not installed" (when using --use-browser)

```bash
pip install playwright
playwright install chromium
```

### Google blocking requests

- Increase delays: Edit `self.min_delay = 5` in code
- Use VPN
- Add `--use-browser` flag
- Process in smaller batches

### Empty Wikipedia results

Normal for smaller companies. The scraper will continue with other sources.

### Website crawl fails

- Try `--use-browser` flag for JavaScript sites
- Some sites have anti-scraping measures
- Check `data/company_profiles_v2_progress.json` for partial results

---

## Example Workflow

### Day 1: Test & Validate

```bash
# Test single company
python scripts/test_company_profiler.py

# Test 5 major companies
python src/utils/company_profiler_v2.py --max-companies 5 --company "maersk" -v
python src/utils/company_profiler_v2.py --max-companies 5 --company "msc" -v

# Review output quality
cat data/company_training_data_*.txt
```

### Day 2-7: Batch Processing

```bash
# Process 100 companies per day
for i in {0..6}; do
    start=$((i * 100))
    python src/utils/company_profiler_v2.py --start-from $start --max-companies 100
    sleep 3600  # 1 hour break between batches
done
```

### Week 2: ML Model Development

```bash
# Combine all training files
cat data/company_training_data_*.txt > data/all_company_data.txt

# Start ML model development
python src/ml/train_wasp_fit_model.py
```

---

## Next Steps

1. âœ… **Test the scraper** - Run on 5-10 companies
2. ğŸ“Š **Verify data quality** - Check output files
3. ğŸ”„ **Batch processing** - Collect data for 500-1000 companies
4. ğŸ¤– **ML model development** - Train fit score predictor
5. ğŸ“ˆ **Integration** - Add to web interface

---

## Comparison: V1 vs V2

| Feature | V1 (Broken) | V2 (Working) |
|---------|-------------|--------------|
| Search engine | DuckDuckGo HTML | Google API-like |
| Success rate | 0% | 80-90% |
| Data per company | 0 bytes | 10-50 KB |
| Sources | 1 (broken) | 4 (working) |
| Wikipedia | âŒ | âœ… |
| Website crawl | âŒ | âœ… |
| ML-ready output | âŒ | âœ… |
| Error handling | Poor | Robust |
| Resume capability | âŒ | âœ… |

---

## Support

For issues or questions:
1. Check verbose output: `-v` flag
2. Review progress file: `data/company_profiles_v2_progress.json`
3. Test single company first
4. Adjust rate limiting if needed

---

**Status**: âœ… Ready for production use
**Recommended**: Start with 10-20 companies to validate
**Goal**: Collect rich company data for ML-powered WASP fit scoring
